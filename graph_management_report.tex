\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{booktabs}
\usepackage{array}

\geometry{margin=2.5cm}

% Code listing style
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny,
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{gray!10},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    tabsize=2,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={\%*}{*)}
}

\title{\textbf{Graph Management Exercises Report}\\
\large Breadth-First Search, Depth-First Search, and Graph Coloring}
\author{Sara Sherif Daoud Saad}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage



\section{Breadth-First Search and Bipartite Graphs}

\subsection{Exercise 1: BFS Distance Computation}

\textbf{Problem:} Using graph traversal algorithms, propose an algorithm that computes the number of edges between a given vertex and all other vertices. 

\textbf{Solution:}  I adjusted the BFS algorithm to find the shortest paths in unweighted graphs by exploring vertices level by level.

\begin{lstlisting}[caption=BFS Distance Computation, label=lst:bfs_distances]
# See exercise1_bfs_distances.py for complete implementation
def compute_distances_from_vertex(graph, start_vertex):
    distances = {}
    for vertex in graph:
        distances[vertex] = float('inf')
    
    distances[start_vertex] = 0
    queue = deque([start_vertex])
    
    while queue:
        current_vertex = queue.popleft()
        for neighbor in graph[current_vertex]:
            if distances[neighbor] == float('inf'):
                distances[neighbor] = distances[current_vertex] + 1
                queue.append(neighbor)
    
    return distances
\end{lstlisting}

\textbf{Time Complexity:} O(V + E) where V is the number of vertices and E is the number of edges.


\textbf{Implementation:} See \texttt{exercise1\_bfs\_distances.py} for complete implementation with custom Queue class.

\subsection{Exercise 2: Odd Cycles Analysis}

\textbf{Problem:} Given the following cycles with even and odd length (with the distances or depths from the grey vertex), what do you think about the case of graphs with an odd cycle (in number of edges)? Is this a characteristic property? State the general case.

\textbf{Solution:} 

\textbf{Observation from the graphs:}
\begin{itemize}
    \item A graph with only even cycles can be bipartite
    \item A graph with an odd cycle cannot be bipartite
\end{itemize}

\textbf{Characteristic property:}
\begin{itemize}
    \item A graph is bipartite $\Leftrightarrow$ it contains no odd-length cycles
\end{itemize}

\textbf{General case:}
\begin{itemize}
    \item Odd cycles break bipartiteness; even cycles do not
\end{itemize}

\textbf{Mathematical Foundation:}
\begin{itemize}
    \item In bipartite graphs, all cycles must have even length
    \item If a graph contains an odd cycle, it cannot be bipartite
    \item This provides a necessary and sufficient condition for bipartiteness
    \item The presence of an odd cycle is a definitive proof that a graph is not bipartite
\end{itemize}

\subsection{Exercise 3: Odd Cycle Detection Algorithm}

\textbf{Problem:} Propose an algorithm that determines if a graph contains an odd cycle.

\textbf{Solution:} Use BFS with vertex coloring to detect odd cycles. If we find a back edge connecting two vertices of the same color, we have found an odd cycle.

\begin{lstlisting}[caption=Odd Cycle Detection, label=lst:odd_cycle]
# See exercise3and5_odd_cycle_detection_bipartite.py for complete implementation
def has_odd_cycle(graph):
    color = {}
    for node in graph:
        if node not in color:
            queue = deque([node])
            color[node] = 0
            
            while queue:
                u = queue.popleft()
                for v in graph[u]:
                    if v not in color:
                        color[v] = 1 - color[u]
                        queue.append(v)
                    elif color[v] == color[u]:
                        return True
    return False
\end{lstlisting}

\textbf{Time Complexity:} O(V + E)
\textbf{Implementation:} See \texttt{exercise3and5\_odd\_cycle\_detection\_bipartite.py} for complete implementation with detailed comments and test cases.

\subsection{Exercise 4: Bipartite Graphs and Odd Cycles}

\textbf{Problem:} In a bipartite graph, can there be a cycle with an odd number of edges? Is this a characteristic property? Justify your answer.

\textbf{Answer:} No, bipartite graphs cannot contain odd cycles. This is indeed a characteristic property.

\textbf{Property:}
\begin{itemize}
    \item Bipartite graphs cannot have odd cycles
\end{itemize}

\textbf{Justification:} Bipartite graphs divide vertices into two sets, all edges go across sets. If there were an odd cycle, you would need an edge connecting vertices in the same set, which is impossible.\\


\textbf{Mathematical Foundation:}
\begin{enumerate}
    \item In a bipartite graph, vertices can be divided into two disjoint sets U and V
    \item Every edge connects a vertex in U to a vertex in V
    \item Any cycle must alternate between sets U and V
    \item To return to the starting vertex, we need an even number of steps
    \item Therefore, all cycles in bipartite graphs have even length
\end{enumerate}

\subsection{Exercise 5: Bipartite Graph Detection}

\textbf{Problem:} Propose an algorithm that allows to determine if a graph is bipartite. Test your algorithm on the following graph. Is it bipartite? Justify your answer.

\textbf{Solution:} BFS-based bipartite detection algorithm.

This is the same BFS coloring algorithm. If you can color the graph with 2 colors without conflict, it's bipartite.


\textbf{Result:} If \texttt{has\_odd\_cycle} returns \texttt{True}, the graph is not bipartite. If \texttt{False}, it is bipartite.

\textbf{Algorithm:} The same BFS coloring algorithm from Exercise 3 can be used to detect bipartiteness.

\section{Depth-First Search and 2-Colorable Graphs}

\subsection{Exercise 1: Link with Previous Exercise}

\textbf{Problem:} What is the link with the previous exercise? Justify your answer.

\textbf{Answer:} 

\textbf{1) Link with the previous exercise}

In the previous exercise, we studied BFS, odd cycles, and bipartite graphs.
A graph is bipartite $\Leftrightarrow$ 2-colorable $\Leftrightarrow$ contains no odd cycle.
So the question of 2-colorability is exactly the same as asking whether the graph is bipartite.

\textbf{Justification:}
\begin{itemize}
\item If a graph is 2-colorable, then all cycles are even (so no odd cycle)
\item If there's an odd cycle, 2-coloring fails
\item Hence, the link is that checking bipartiteness (with BFS in the previous exercise) is equivalent to checking 2-colorability (with DFS here)
\end{itemize}



\textbf{Implementation:} See \texttt{dfs\_exercise2\_2colorability\_algorithm.py} for detailed analysis.

\subsection{Exercise 2: 2-Colorability Algorithm}

\textbf{Problem:} We want to write an algorithm, inspired by DFS search which takes as input a graph G(V, E) and which returns a pair (result, color) where result is true if the graph is colorable, false otherwise and color is a dictionary associating a color 0 or 1 to each vertex. This algorithm should stop as soon as possible when the graph is not 2-colorable. Propose an iterative version or a recursive version.

\textbf{Solution:} 

We need an algorithm that:
\begin{itemize}
\item Uses DFS traversal
\item Assigns alternating colors (0 and 1)
\item Stops immediately when a conflict (same color on adjacent vertices) is found
\item Returns (result, color)
\end{itemize}

\textbf{Recursive DFS implementation:}

\begin{lstlisting}[caption=Recursive DFS 2-Colorability Detection, label=lst:dfs_recursive]
def is_2_colorable_dfs(graph):
    color = {}
    
    def dfs(node, c):
        color[node] = c
        for neighbor in graph[node]:
            if neighbor not in color:
                if not dfs(neighbor, 1 - c):  # alternate color
                    return False
            elif color[neighbor] == color[node]:
                return False  # conflict: same color for adjacent nodes
        return True
    
    # handle disconnected graphs
    for v in graph:
        if v not in color:
            if not dfs(v, 0):
                return False, color
    return True, color
\end{lstlisting}

\textbf{Iterative DFS implementation (stack-based):}

\begin{lstlisting}[caption=Iterative DFS 2-Colorability Detection, label=lst:dfs_iterative]
def is_2_colorable_dfs_iterative(graph):
    color = {}
    
    for start in graph:
        if start not in color:
            stack = [(start, 0)]
            
            while stack:
                node, c = stack.pop()
                
                if node in color:
                    if color[node] != c:
                        return False, color  # conflict
                    continue
                
                color[node] = c
                
                for neighbor in graph[node]:
                    stack.append((neighbor, 1 - c))
    
    return True, color
\end{lstlisting}

\textbf{Example usage:}
\begin{lstlisting}[caption=Example Usage, label=lst:example_usage]
graph = {
    0: [1, 2],
    1: [0, 3],
    2: [0, 3],
    3: [1, 2]
}

print(is_2_colorable_dfs(graph))
# Output: (True, {0:0, 1:1, 2:1, 3:0}) â†’ the graph is 2-colorable.
\end{lstlisting}

If there's an odd cycle, the function stops early and returns (False, color).

\textbf{Features:}
\begin{itemize}
\item Early termination when conflict is found
\item Returns (result, color) pair as specified
\item Both iterative and recursive versions
\item Time complexity: O(V + E)
\item Handles disconnected graphs
\end{itemize}

\section{Dijkstra's Algorithm Results}

\subsection{Step-by-Step Execution of Dijkstra's Algorithm}

I'll solve this step-by-step using Dijkstra's algorithm with source vertex $s = a$.

\subsubsection{Initial Setup}

\begin{itemize}
    \item $\text{dist} = \{a: 0\}$
    \item $P = \emptyset$ (processed vertices)
    \item $\text{dist}[v] = \infty$ for all $v \neq a$
\end{itemize}

\subsubsection{Iteration-by-Iteration Execution}

\textbf{Iteration 1:}
\begin{itemize}
    \item Select $w = a$ (min distance = 0)
    \item $P = \{a\}$
    \item Update neighbors of $a$:
    \begin{itemize}
        \item $f$: $\text{dist}[f] = \min(\infty, 0 + 3) = 3$, predecessor$[f] = a$
        \item $g$: $\text{dist}[g] = \min(\infty, 0 + 1) = 1$, predecessor$[g] = a$
    \end{itemize}
\end{itemize}

Current distances: $\{a: 0, f: 3, g: 1, b: \infty, e: \infty, c: \infty, d: \infty\}$

\textbf{Iteration 2:}
\begin{itemize}
    \item Select $w = g$ (min unprocessed distance = 1)
    \item $P = \{a, g\}$
    \item Update neighbors of $g$:
    \begin{itemize}
        \item $f$: $\text{dist}[f] = \min(3, 1 + 1) = 2$, predecessor$[f] = g$
        \item $e$: $\text{dist}[e] = \min(\infty, 1 + 2) = 3$, predecessor$[e] = g$
    \end{itemize}
\end{itemize}

Current distances: $\{a: 0, g: 1, f: 2, e: 3, b: \infty, c: \infty, d: \infty\}$

\textbf{Iteration 3:}
\begin{itemize}
    \item Select $w = f$ (min unprocessed distance = 2)
    \item $P = \{a, g, f\}$
    \item Update neighbors of $f$:
    \begin{itemize}
        \item $b$: $\text{dist}[b] = \min(\infty, 2 + 4) = 6$, predecessor$[b] = f$
        \item $e$: $\text{dist}[e] = \min(3, 2 + 2) = 3$ (no change)
    \end{itemize}
\end{itemize}

Current distances: $\{a: 0, g: 1, f: 2, e: 3, b: 6, c: \infty, d: \infty\}$

\textbf{Iteration 4:}
\begin{itemize}
    \item Select $w = e$ (min unprocessed distance = 3)
    \item $P = \{a, g, f, e\}$
    \item Update neighbors of $e$:
    \begin{itemize}
        \item $c$: $\text{dist}[c] = \min(\infty, 3 + 1) = 4$, predecessor$[c] = e$
        \item $d$: $\text{dist}[d] = \min(\infty, 3 + 5) = 8$, predecessor$[d] = e$
    \end{itemize}
\end{itemize}

Current distances: $\{a: 0, g: 1, f: 2, e: 3, c: 4, b: 6, d: 8\}$

\textbf{Iteration 5:}
\begin{itemize}
    \item Select $w = c$ (min unprocessed distance = 4)
    \item $P = \{a, g, f, e, c\}$
    \item Update neighbors of $c$:
    \begin{itemize}
        \item $b$: $\text{dist}[b] = \min(6, 4 + 3) = 6$ (no change)
        \item $d$: $\text{dist}[d] = \min(8, 4 + 2) = 6$, predecessor$[d] = c$
    \end{itemize}
\end{itemize}

Current distances: $\{a: 0, g: 1, f: 2, e: 3, c: 4, b: 6, d: 6\}$

\textbf{Iterations 6 \& 7:}
\begin{itemize}
    \item Process $b$ (distance 6) and $d$ (distance 6)
    \item No more updates needed
\end{itemize}

\subsubsection{Final Results}

Shortest distances from vertex $a$:

\begin{table}[h]
\centering
\begin{tabular}{ccc}
\toprule
Destination & Distance & Path \\
\midrule
$a \rightarrow a$ & 0 & $a$ \\
$a \rightarrow g$ & 1 & $a \rightarrow g$ \\
$a \rightarrow f$ & 2 & $a \rightarrow g \rightarrow f$ \\
$a \rightarrow e$ & 3 & $a \rightarrow g \rightarrow e$ \\
$a \rightarrow c$ & 4 & $a \rightarrow g \rightarrow e \rightarrow c$ \\
$a \rightarrow b$ & 6 & $a \rightarrow g \rightarrow f \rightarrow b$ \\
$a \rightarrow d$ & 6 & $a \rightarrow g \rightarrow e \rightarrow c \rightarrow d$ \\
\bottomrule
\end{tabular}
\caption{Shortest paths from node a to all other nodes}
\end{table}

\section{Matrix Multiplication and Graph Powers}

\subsection{Exercise: Matrix Multiplication \& Power}

\subsubsection{1) Different Representations of These Graphs}

\textbf{Left Graph (Undirected):}

\textbf{Edge List:}
\begin{itemize}
    \item (0,1), (0,4), (1,2), (1,5), (2,3), (3,5), (4,5)
\end{itemize}

\textbf{Adjacency Matrix A:}
\begin{equation}
A = \begin{bmatrix}
0 & 1 & 0 & 0 & 1 & 0 \\
1 & 0 & 1 & 0 & 0 & 1 \\
0 & 1 & 0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & 0 & 1 \\
0 & 1 & 0 & 1 & 1 & 0
\end{bmatrix}
\end{equation}

\textbf{Adjacency List:}
\begin{itemize}
    \item 0: \{1, 4\}
    \item 1: \{0, 2, 5\}
    \item 2: \{1, 3\}
    \item 3: \{2, 5\}
    \item 4: \{0, 5\}
    \item 5: \{1, 3, 4\}
\end{itemize}

\textbf{Right Graph (Directed):}

\textbf{Edge List:}
\begin{itemize}
    \item (0,1), (0,4), (1,5), (2,3), (3,3), (4,5), (5,4)
\end{itemize}

\textbf{Adjacency Matrix A:}
\begin{equation}
A = \begin{bmatrix}
0 & 1 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 1 & 0
\end{bmatrix}
\end{equation}

\textbf{Adjacency List:}
\begin{itemize}
    \item 0: \{1, 4\}
    \item 1: \{5\}
    \item 2: \{3\}
    \item 3: \{3\}
    \item 4: \{5\}
    \item 5: \{4\}
\end{itemize}

\subsubsection{2) Compute AÂ², AÂ³ and Meaning of A^r_ij}

\textbf{For the Left Graph (Undirected):}

\textbf{AÂ²:}
\begin{equation}
A^2 = \begin{bmatrix}
2 & 0 & 1 & 0 & 0 & 2 \\
0 & 3 & 0 & 2 & 1 & 0 \\
1 & 0 & 2 & 0 & 0 & 2 \\
0 & 2 & 0 & 2 & 1 & 0 \\
0 & 1 & 0 & 1 & 2 & 0 \\
2 & 0 & 2 & 0 & 0 & 3
\end{bmatrix}
\end{equation}

\textbf{AÂ³:}
\begin{equation}
A^3 = \begin{bmatrix}
0 & 5 & 0 & 4 & 4 & 0 \\
5 & 0 & 6 & 0 & 0 & 7 \\
0 & 6 & 0 & 5 & 3 & 0 \\
4 & 0 & 5 & 0 & 0 & 6 \\
4 & 0 & 3 & 0 & 0 & 5 \\
0 & 7 & 0 & 6 & 5 & 0
\end{bmatrix}
\end{equation}

\textbf{For the Right Graph (Directed):}

\textbf{AÂ²:}
\begin{equation}
A^2 = \begin{bmatrix}
0 & 0 & 0 & 0 & 1 & 2 \\
0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}
\end{equation}

\textbf{AÂ³:}
\begin{equation}
A^3 = \begin{bmatrix}
0 & 0 & 0 & 0 & 1 & 1 \\
0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 1 & 0
\end{bmatrix}
\end{equation}

\textbf{Meaning of A^r_ij:}

$A^r_{ij}$ represents the number of walks (paths that may repeat vertices) of length exactly $r$ from vertex $i$ to vertex $j$.

\textbf{Examples:}
\begin{itemize}
    \item $A^2[0,5] = 2$ (left graph) means there are 2 walks of length 2 from vertex 0 to vertex 5: $(0 \rightarrow 1 \rightarrow 5)$ and $(0 \rightarrow 4 \rightarrow 5)$
    \item $A^3[1,5] = 7$ (left graph) means there are 7 walks of length 3 from vertex 1 to vertex 5
\end{itemize}

\subsubsection{3) Complexity of A^r and Possible Reduction}

\textbf{Naive Approach:}

Computing $A^r$ by repeated matrix multiplication:
\begin{itemize}
    \item $A^2 = A \times A$
    \item $A^3 = A^2 \times A$
    \item $A^r = A^{r-1} \times A$
\end{itemize}

For an $n \times n$ matrix, one multiplication takes $O(n^3)$ time (or $O(n^{2.37})$ with Strassen's algorithm).
Computing $A^r$ requires $(r-1)$ multiplications: \textbf{$O(r \cdot n^3)$}

\textbf{Optimized Approach - Exponentiation by Squaring:}

We can reduce the number of multiplications using binary exponentiation:
\begin{itemize}
    \item Compute $A^1, A^2, A^4, A^8, \ldots$, by repeated squaring
    \item Combine results based on binary representation of $r$
\end{itemize}

\textbf{Complexity:} $O(\log r \cdot n^3)$ or $O(\log r \cdot n^{2.37})$ with fast matrix multiplication

\textbf{Example:} To compute $A^{10}$:
\begin{itemize}
    \item $10 = 1010_2 = 8 + 2$
    \item Compute: $A^1 \rightarrow A^2 \rightarrow A^4 \rightarrow A^8$
    \item Result: $A^{10} = A^8 \times A^2$
    \item Only 4 multiplications instead of 9!
\end{itemize}

\textbf{Reduction:} Yes, from $O(r \cdot n^3)$ to \textbf{$O(\log r \cdot n^3)$} - exponential improvement in $r$!

\section{Linear Algebra Exercises}

\subsection{Exercise 1: Matrix Analysis}

\textbf{Problem:} What could you say about these matrices?

Let me call them $A = \begin{pmatrix} -1 & \frac{3}{2} \\ 1 & -1 \end{pmatrix}$, $B = \begin{pmatrix} -1 & \frac{3}{2} \\ \frac{2}{3} & -1 \end{pmatrix}$, $C = \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix}$

\textbf{Observations:}
\begin{itemize}
    \item \textbf{C is the identity matrix $I_3$}
    \item \textbf{A is not symmetric} ($A \neq A^T$)
    \item \textbf{B is symmetric} ($B = B^T$)
    \item Both A and B have trace = -2 and similar structure
    \item C is orthogonal, symmetric, and idempotent
\end{itemize}

\subsection{Exercise 2: Matrix Powers and Diagonalization}

\textbf{Problem:} Show that $A^n = X\Lambda^nX^{-1}$

\textbf{Proof:}
If A is diagonalizable, then $A = X\Lambda X^{-1}$ where $\Lambda$ is diagonal matrix of eigenvalues and X is matrix of eigenvectors.

Then:
\begin{itemize}
    \item $A^2 = (X\Lambda X^{-1})(X\Lambda X^{-1}) = X\Lambda(X^{-1}X)\Lambda X^{-1} = X\Lambda^2X^{-1}$
    \item $A^3 = A^2 \cdot A = (X\Lambda^2X^{-1})(X\Lambda X^{-1}) = X\Lambda^3X^{-1}$
\end{itemize}

By induction:
\begin{itemize}
    \item \textbf{Base case:} $A^1 = X\Lambda^1X^{-1}$ âœ“
    \item \textbf{Inductive step:} If $A^k = X\Lambda^kX^{-1}$, then $A^{k+1} = A^k \cdot A = (X\Lambda^kX^{-1})(X\Lambda X^{-1}) = X\Lambda^{k+1}X^{-1}$ âœ“
\end{itemize}

Therefore \textbf{$A^n = X\Lambda^nX^{-1}$} for all $n \geq 1$.

\subsection{Exercise 3: Eigenvalues and Eigenvectors of A^T A and AA^T}

\textbf{Problem:} Find eigenvalues and unit eigenvectors of $A^T A$ and $AA^T$

Given: $A = \begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}$ (Fibonacci matrix)

\textbf{Computing $A^T A$:}
$$A^T A = \begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}\begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix} = \begin{pmatrix} 2 & 1 \\ 1 & 1 \end{pmatrix}$$

\textbf{Eigenvalues of $A^T A$:}
$$\det(A^T A - \lambda I) = \det\begin{pmatrix} 2-\lambda & 1 \\ 1 & 1-\lambda \end{pmatrix} = (2-\lambda)(1-\lambda) - 1 = \lambda^2 - 3\lambda + 1 = 0$$

$$\lambda = \frac{3 \pm \sqrt{9-4}}{2} = \frac{3 \pm \sqrt{5}}{2}$$

\textbf{$\lambda_1 = \frac{3+\sqrt{5}}{2} \approx 2.618$} (golden ratio squared: $\phi^2$)

\textbf{$\lambda_2 = \frac{3-\sqrt{5}}{2} \approx 0.382$}

\textbf{Unit eigenvectors of $A^T A$:}

For $\lambda_1 = \frac{3+\sqrt{5}}{2}$:
$$v_1 = \frac{1}{\sqrt{2+\sqrt{5}}}\begin{pmatrix} \frac{1+\sqrt{5}}{2} \\ 1 \end{pmatrix}$$

For $\lambda_2 = \frac{3-\sqrt{5}}{2}$:
$$v_2 = \frac{1}{\sqrt{2-\sqrt{5}}}\begin{pmatrix} \frac{1-\sqrt{5}}{2} \\ 1 \end{pmatrix}$$

\textbf{Computing $AA^T$:}
$$AA^T = \begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix}\begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix} = \begin{pmatrix} 2 & 1 \\ 1 & 1 \end{pmatrix}$$

\textbf{Note:} $AA^T = A^T A$ in this case! So eigenvalues and eigenvectors are the same.

\subsection{Exercise 4: Matrix Decomposition Analysis}

\textbf{Problem:} Without multiplying S, find determinant, eigenvalues, eigenvectors, and why S is positive definite

$$S = \begin{bmatrix} \cos \theta & -\sin \theta \\ \sin \theta & \cos \theta \end{bmatrix}\begin{bmatrix} 2 & 0 \\ 0 & 5 \end{bmatrix}\begin{bmatrix} \cos \theta & \sin \theta \\ -\sin \theta & \cos \theta \end{bmatrix}$$

Let $R(\theta) = \begin{bmatrix} \cos \theta & -\sin \theta \\ \sin \theta & \cos \theta \end{bmatrix}$ (rotation matrix)

Then $S = R(\theta) \cdot D \cdot R(\theta)^T$ where $D = \text{diag}(2, 5)$

\textbf{Determinant:}
$$\det(S) = \det(R) \cdot \det(D) \cdot \det(R^T) = 1 \cdot 10 \cdot 1 = \textbf{10}$$

\textbf{Eigenvalues:}
S is similar to D (conjugate by rotation), so eigenvalues are \textbf{$\lambda_1 = 2, \lambda_2 = 5$}

\textbf{Eigenvectors:}
The eigenvectors of D are $e_1 = (1,0)^T$ and $e_2 = (0,1)^T$

The eigenvectors of S are rotated versions:
\begin{itemize}
    \item \textbf{$v_1 = (\cos \theta, \sin \theta)^T$} for $\lambda_1 = 2$
    \item \textbf{$v_2 = (-\sin \theta, \cos \theta)^T$} for $\lambda_2 = 5$
\end{itemize}

\textbf{Why S is positive definite:}
\begin{itemize}
    \item All eigenvalues are positive ($2 > 0, 5 > 0$)
    \item S is symmetric ($S = S^T$)
    \item Therefore S is \textbf{positive definite}
\end{itemize}

\subsection{Exercise 5: Positive Definite Conditions}

\textbf{Problem:} For what c and d are S and T positive definite?

$$S = \begin{pmatrix} c & 1 & 1 \\ 1 & c & 1 \\ 1 & 1 & c \end{pmatrix}, \quad T = \begin{pmatrix} 1 & 2 & 3 \\ 2 & d & 4 \\ 3 & 4 & 5 \end{pmatrix}$$

\textbf{For S to be positive definite:}
Using Sylvester's criterion (all leading principal minors > 0):

\begin{enumerate}
    \item $c > 0$
    \item $\det\begin{pmatrix} c & 1 \\ 1 & c \end{pmatrix} = c^2 - 1 > 0 \implies c > 1$
    \item $\det(S) = c^3 + 2 - 3c = (c-1)^2(c+2) > 0 \implies c > 1$ (since $c+2 > 0$ when $c > 0$)
\end{enumerate}

\textbf{Answer for S: $c > 1$}

\textbf{For T to be positive definite:}
\begin{enumerate}
    \item $1 > 0$ âœ“
    \item $\det\begin{pmatrix} 1 & 2 \\ 2 & d \end{pmatrix} = d - 4 > 0 \implies d > 4$
    \item $\det(T) = 1(5d - 16) - 2(10 - 12) + 3(8 - 3d) = 5d - 16 + 4 + 24 - 9d = 12 - 4d > 0 \implies d < 3$
\end{enumerate}

But we need $d > 4$ AND $d < 3$, which is \textbf{impossible!}

\textbf{Answer for T: No values of d make T positive definite} (T has rank â‰¤ 2 since rows are nearly linearly dependent)

\subsection{Exercise 6: Eigenvalues of Matrix Powers}

\textbf{Problem:} Show if $\lambda_1, \lambda_2, \ldots, \lambda_n$ are eigenvalues of A, then $A^m$ has eigenvalues $\lambda_1^m, \lambda_2^m, \ldots, \lambda_n^m$

\textbf{Proof:}
If $Av = \lambda v$ (v is eigenvector with eigenvalue $\lambda$), then:
\begin{itemize}
    \item $A^2v = A(Av) = A(\lambda v) = \lambda(Av) = \lambda^2v$
    \item $A^3v = A(A^2v) = A(\lambda^2v) = \lambda^2(Av) = \lambda^3v$
\end{itemize}

By induction: \textbf{$A^mv = \lambda^mv$}

Therefore, if $\lambda$ is an eigenvalue of A with eigenvector v, then \textbf{$\lambda^m$ is an eigenvalue of $A^m$ with the same eigenvector v}.

\subsection{Exercise 7: Determinant of Orthogonal Matrices}

\textbf{Problem:} What is the determinant of any orthogonal matrix?

An orthogonal matrix Q satisfies $Q^TQ = I$

Taking determinants: $\det(Q^TQ) = \det(I)$

$\det(Q^T) \cdot \det(Q) = 1$

$\det(Q)^2 = 1$

\textbf{Answer: $\det(Q) = \pm 1$}

\subsection{Exercise 8: Laplacian Matrix Properties}

\textbf{Problem:} Laplacian matrix properties

For an undirected graph, the \textbf{Laplacian matrix $L = D - A$} where:
\begin{itemize}
    \item D = diagonal degree matrix
    \item A = adjacency matrix
\end{itemize}

\textbf{Properties to show:}

\textbf{(a) L is symmetric:}
Since A is symmetric (undirected graph) and D is diagonal (symmetric), $L = D - A$ is symmetric. âœ“

\textbf{(b) L is positive semi-definite:}
For any vector x:
$$x^TLx = x^T(D-A)x = \sum_i d_i x_i^2 - \sum_{i,j} A_{ij} x_i x_j = \frac{1}{2}\sum_{(i,j) \in E} (x_i - x_j)^2 \geq 0$$

Therefore L is positive semi-definite. âœ“

\textbf{(c) L has 0 as an eigenvalue:}
$$L\mathbf{1} = (D-A)\mathbf{1} = D\mathbf{1} - A\mathbf{1} = \mathbf{0}$$ (since each row sum of A equals the degree)

The vector $\mathbf{1} = (1,1,\ldots,1)^T$ is an eigenvector with eigenvalue 0. âœ“

This is the smallest eigenvalue because L is positive semi-definite (all eigenvalues â‰¥ 0).
\section{Random Walk on Graphs}
\subsection{Proof 1: Lazy Random Walk is still Stochastic}

A \emph{lazy random walk} on a graph \( G = (V, E) \) is defined such that at each step:
\begin{itemize}
    \item with probability \( \frac{1}{2} \), the walker stays at the current node (self cycles),
    \item with probability \( \frac{1}{2} \), the walker moves to a neighbor chosen at random from a unform distribution.
\end{itemize}

from the definition of the simple random walk, \( A \) be the adjacency matrix and \( D = \mathrm{diag}(d_1, \dots, d_n) \) the degree matrix.  
The transition matrix of a simple random walk is given by
\[
P = D^{-1}A.
\]
For the lazy random walk:
\begin{enumerate}
    \item With probability \( \tfrac{1}{2} \), the walker remains on the same node.
    This is represented by the \emph{identity matrix} \( I \), since
    \[
    I_{ij} =
    \begin{cases}
    1, & \text{if } i = j,\\[4pt]
    0, & \text{otherwise.}
    \end{cases}
    \]
    It encodes a self-loop transition (staying at node \( i \)).
    \item With probability \( \tfrac{1}{2} \), the walker follows the standard random walk step given by \( P = D^{-1}A \).
\end{enumerate}
\[
P_{\text{lazy}} = \frac{1}{2}I + \frac{1}{2}P = \frac{1}{2}\left(I + D^{-1}A\right).
\]

\paragraph{To proof that \(P_{\text{lazy}}\) is stochastic.}
We must show that each row of \( P_{\text{lazy}} \) sums to 1.  
For the \( i^{\text{th}} \) row:
\[
\sum_{j}(P_{\text{lazy}})_{ij}
= \frac{1}{2}\sum_{j}I_{ij} + \frac{1}{2}\sum_{j}P_{ij}
= \frac{1}{2}(1 + 1) = 1.
\]
Hence \( P_{\text{lazy}} \) is row-stochastic.

\paragraph{Consequence.}
The addition of self-loops (\( \frac{1}{2}I \)) makes the chain \emph{aperiodic} and thus \emph{primitive}.  
By the Perronâ€“Frobenius theorem, \( P_{\text{lazy}} \) admits a unique stationary distribution \( \pi \) satisfying
\[
\pi = \pi P_{\text{lazy}}, \quad \text{with} \quad \sum_i \pi_i = 1.
\]










\section{Code References}

\begin{itemize}
    \item \texttt{exercise1\_bfs\_distances.py} - BFS distance computation
    \item \texttt{exercise3and5\_odd\_cycle\_detection\_bipartite.py} - Odd cycle detection and bipartite graphs
    \item \texttt{dfs\_exercise2\_2colorability\_algorithm.py} - 2-colorability algorithm
\end{itemize}
\end{document}
